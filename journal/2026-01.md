# 2026年1月学习笔记

## 1.05 - 学习 LangChain（失败）

### 尝试动机
看了很多人推荐 LangChain，说能简化 Agent 开发，决定试试。

### 安装
```bash
pip install langchain openai
```

### 问题
1. **文档太复杂**
   - 几十个概念：Chain, Agent, Tool, Memory, Callback...
   - 每个概念又有很多子类和变体

2. **例子跑不通**
   - 官方示例代码报错：`ImportError: cannot import name 'XYZ'`
   - 版本差异？还是文档过时？

3. **放弃**
   - 花 3 小时在安装和调试上，还没有到实际用
   - 感觉到：对于一个初学者，LangChain 的学习曲线太陡了

### 结论
- **暂时不用** LangChain，先自己从零开始理解概念
- 等自己有基础了，再回来学框架

---

## 1.12 - 自己实现工具调用

### 背景
看到 AutoGPT 的视频，Agent 能自己搜索网页、写代码。决定自己实现一个最简版本。

### 第一次尝试：用正则匹配

```python
def extract_tool_call(response):
    if "use_calculator" in response:
        return run_calculator()
```

**问题：** LLM 不一定按你想要的格式输出

### 第二次尝试：用 JSON 模式

```python
response = client.chat.completions.create(
    messages=[...],
    response_format={"type": "json_object"}
)
```

**问题：** OpenAI 的 JSON 模式有时候返回 null，有时候格式错

### 第三次尝试：提示词工程

```python
prompt = """
如果需要调用工具，请按以下 JSON 格式输出：
{
    "tool": "tool_name",
    "args": {...}
}
"""
```

**问题：** 有时能成功，有时不行，不稳定

### 最后的方案：多步处理

1. 先让 LLM 判断是否需要工具
2. 如果需要，再调用 LLM 让它生成工具调用的 JSON
3. 解析 JSON 并执行工具
4. 把结果给 LLM，让它在最终回复中总结

**代码：** 见 `v2/tool_calling.py`

**结论：**
- 不稳定，但能用
- 每次要多调用一次 API（开销大）
- 准备学习更好的方法（比如 OpenAI 的 function calling）

---

## 1.25 - 学习 OpenAI Function Calling

### 背景
看到 OpenAI 文档，发现已经有官方的函数调用功能，不用自己解析 JSON 了。

### 尝试

```python
import openai

client = openai.OpenAI()

response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[...],
    tools=[
        {
            "type": "function",
            "function": {
                "name": "calculator",
                "description": "执行数学计算",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "expression": {
                            "type": "string",
                            "description": "数学表达式"
                        }
                    },
                    "required": ["expression"]
                }
            }
        }
    ]
)
```

### 效果
✅ **太方便了！**
- LLM 自己判断是否调用函数
- 返回的格式稳定，`response.tool_calls` 直接是结构化数据
- 不需要手动解析 JSON

### 问题
1. **JSON Schema 不好写**
   - 要定义 type, properties, required...
   - 稍微复杂一点的参数，schema 就写不明白了

2. **多轮工具调用**
   - 有时 LLM 一次要调用 2 个函数（比如先查资料再计算）
   - 但返回的 `tool_calls` 只有最后一个
   - 需要手动循环处理

### 结论
- 确实比自己写正则匹配靠谱
- 但 JSON Schema 的书写还是需要练习
- **决定：** 以后的项目都用 function calling，不用自己解析了

---

## 本月小结

✅ **放弃的：**
- LangChain（太复杂，不适合当前水平）

✅ **掌握的：**
- OpenAI 的 Function Calling
- 工具调用的基本流程

❌ **困惑的：**
- 复杂工具的 JSON Schema 怎么写？
- 多步骤任务怎么编排（Tool A 的结果作为 Tool B 的输入）？

📝 **下一步：**
- 学习记忆系统（对话历史不够用）
- 看看向量数据库
